# RWKV 파인튜닝

## 1. 알고리즘 설명

RWKV(Receptance Weighted Key Value)는 트랜스포머와 RNN의 장점을 결합한 아키텍처로, 긴 컨텍스트를 효율적으로 처리할 수 있습니다. 어텐션 대신 시간 혼합(time-mixing)과 채널 혼합(channel-mixing) 레이어를 사용합니다.

## 2. 파라미터 설명

| 파라미터 | 설명 | 일반적인 값 |
|-----------|------|------------|
| learning_rate | 학습률 | 1e-5, 5e-5 |
| batch_size | 배치 크기 | 8, 16, 32 |
| ctx_len | 컨텍스트 길이 | 1024, 2048, 4096 |
| epochs | 학습 에폭 | 3, 5 |

## 3. 주요 모델에 대한 GPU 사양

| 모델명 | 모델 크기 | 최소 GPU 사양 | 권장 GPU 사양 |
|--------|-----------|--------------|--------------|
| RWKV-430M | 430M | VRAM 6GB (1660) | VRAM 8GB (2080) |
| RWKV-1.5B | 1.5B | VRAM 8GB (2080) | VRAM 16GB (3090) |
| RWKV-7B | 7B | VRAM 16GB (3090) | VRAM 24GB (4090) |

## 4. 핸즈온 Example

[이 섹션에는 실제 파인튜닝에 사용할 수 있는 코드 예제 또는 실습 예시를 추가합니다.]
