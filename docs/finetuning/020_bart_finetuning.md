# BART 파인튜닝

## 1. 알고리즘 설명

BART(Bidirectional and Auto-Regressive Transformers)는 인코더-디코더 구조로, 요약, 번역, 생성 등 시퀀스-투-시퀀스 태스크에 강점을 가진 모델입니다. 입력 텍스트를 손상시킨 후 복원하는 방식으로 사전학습됩니다.

## 2. 파라미터 설명

| 파라미터 | 설명 | 일반적인 값 |
|-----------|------|------------|
| learning_rate | 학습률 | 3e-5, 5e-5, 1e-4 |
| batch_size | 배치 크기 | 8, 16, 32 |
| max_input_length | 입력 최대 길이 | 512, 1024 |
| max_output_length | 출력 최대 길이 | 64, 128, 256 |
| epochs | 학습 에폭 | 3, 5 |

## 3. 주요 모델에 대한 GPU 사양

| 모델명 | 모델 크기 | 최소 GPU 사양 | 권장 GPU 사양 |
|--------|-----------|--------------|--------------|
| BART-base | 140M | VRAM 6GB (1660) | VRAM 8GB (2080) |
| BART-large | 400M | VRAM 8GB (2080) | VRAM 16GB (3090) |
| mBART-50 | 610M | VRAM 12GB (3080) | VRAM 16GB (3090) |

## 4. 핸즈온 Example

[이 섹션에는 실제 파인튜닝에 사용할 수 있는 코드 예제 또는 실습 예시를 추가합니다.]
