# Prompt Tuning 파인튜닝

## 1. 알고리즘 설명

Prompt Tuning은 입력 프롬프트에 학습 가능한 임베딩을 추가하여, 전체 모델 파라미터는 고정하고 임베딩만 학습하는 파인튜닝 방법입니다. 적은 파라미터와 연산으로 다양한 태스크에 적용할 수 있습니다.

## 2. 파라미터 설명

| 파라미터 | 설명 | 일반적인 값 |
|-----------|------|------------|
| prompt_length | 프롬프트 임베딩 길이 | 10, 20, 50 |
| learning_rate | 학습률 | 1e-4, 5e-5 |
| dropout | 드롭아웃 비율 | 0.1, 0.2 |

## 3. 주요 모델에 대한 GPU 사양

| 모델명 | 모델 크기 | 최소 GPU 사양 | 권장 GPU 사양 |
|--------|-----------|--------------|--------------|
| GPT-2 | 1.5B | VRAM 4GB (2060) | VRAM 8GB (2080) |
| T5-base | 220M | VRAM 4GB (2060) | VRAM 8GB (2080) |
| Llama-7B | 7B | VRAM 8GB (2080) | VRAM 16GB (3090) |

## 4. 핸즈온 Example

[이 섹션에는 실제 파인튜닝에 사용할 수 있는 코드 예제 또는 실습 예시를 추가합니다.]
